{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6023a9d2-d1b5-4383-9701-7131b0a6ed0b",
   "metadata": {},
   "source": [
    "### Optimisation of a Bioprocess with Multifidelity Bayesian Optimisation\n",
    "\n",
    "\n",
    "#### Hackathon Breif\n",
    "This hackathon involves the optimisation of a simulated bioprocess at process scale utilising CHO cells to produce a desired protein. Experimentally, this would involve a resource-intensive screening campaign involving the growth and feeding of cells under precise conditions (temperature, pH, feed amount, fidelity, etc.) to maximize the production of a desired product. This hackathon offers a simulated method of mapping bioprocess input parameters to a final predicted titre concentration: a measure of cell productivity. The simulations are based on various kinetic parameters which are unique to the type of cells used. For the final scoring, a different set of cell kinetic parameters will be used to evaluate your algorithm. \n",
    "\n",
    "#### Inputs and Outputs\n",
    "Inputs to the bioprocess includes 5 vairables: the temperature [°C], pH and the concentration of feed [mM] at 3 different timepoints over 150 minutes. The output is the concentration of the titre (desired product) [g/L]. The goal is to obtain the input variables that correspond to the highest obtained titre. \n",
    "\n",
    "The bounds of the inputs are as follows: \n",
    "\n",
    "```\n",
    "temperature [°C]               -> 30 - 40\n",
    "pH                             -> 6 - 8\n",
    "first feed concentration [mM]  -> 0 - 50\n",
    "second feed concentration [mM] -> 0 - 50\n",
    "third feed concentration [mM]  -> 0 - 50\n",
    "```\n",
    "\n",
    "#### Fidelities and Running the simulation\n",
    "The simulations can be perfomed at 3 levels of fidelities with an associated accuracy and costs. These fidelities corresponds to a different reactor type and scale used. \n",
    "\n",
    "```\n",
    "Lowest fideility: 3L reactor with 1 feeding timepoint at 60 mins.\n",
    "Realtive cost: 10\n",
    "Remarks: The feeding concentration is taken as the second feed concentration. Lowest accuracy, but also lowest cost. \n",
    "\n",
    "Middle fidelity: 3L reactor with 3 feeding timepoints at 40, 80, 120 mins.\n",
    "Relative cost: 575\n",
    "Remarks: -\n",
    "\n",
    "Highest fidelity: 15L reactor with 3 feeding timepoints at 40, 80, 120 mins.\n",
    "Relative cost: 2100\n",
    "Remarks: Highest accuracy but high cost.\n",
    "```\n",
    "\n",
    "To run an experiment, one can use the `conduct_experiment(X)` function -> this is your objective function. The inputs to this function is a matrix of shape (N, 6) where N is the number of data points and 6 refers to the total number of variables in the following order: `[temperature, pH, feed1, feed2, feed3, fidelity]`. The fidelities are refered to as integers where `0` corresponds to the lowest fidelity, `1` with the middle and `2` with the highest fidelity. An example is shown below. \n",
    "\n",
    "``` python\n",
    "import numpy as np\n",
    "from C_Bioprocess_Utils.virtual_lab import conduct_experiment\n",
    "\n",
    "\n",
    "def obj_func(X):\n",
    "\treturn (-np.array(conduct_experiment(X))) #negative placed if optimisation performed is minimisation\n",
    "\n",
    "X_initial = np.array([[33, 6.25, 10, 20, 20, 0],\n",
    "                      [38, 8, 20, 10, 20, 0]])\n",
    "Y_initial = conduct_experiment(X_initial)\n",
    "print(Y_initial)\n",
    "```\n",
    "\n",
    "#### Goal and Submission\n",
    "Your goal is to develop a Bayesian Optimisation class to obtain the set of inputs which maximizes the titre. You have a **budget of 10000** (observe the cost of running each fidelity), a maximum runtime (on the intructor's computer - be aware of how large the search space becomes especially with 6 dimensions!) and starting with a maximum of 6 training points. (Remember, you have to have at least 2 points for each variable for the covariance matrix to be calculated.)\n",
    "\n",
    "Please submit your BO class (and GP class) along with the execution block as a .py file to the instructor. A different cell type (with different simulation parameters and maxima) will be used for scoring.\n",
    "\n",
    "This hackathon will be scored based on the sum of the titre concentration obtained. The score will be penalised by your algorithm's runtime in seconds. \n",
    "\n",
    "You must stay within the allocated budget! This will be checked, and if exceeded, your submission will be disqualified!\n",
    "\n",
    "#### Goal and Submission\n",
    "Your goal is to develop a Bayesian Optimisation class to obtain the set of inputs which **maximizes the titre at the highest fideility**. You have a **budget of 15000** (observe the cost of running each fidelity) and starting with a maximum of 7 training points that is not a part of the budget. (Remember, you have to have at least 2 points for each variable for the covariance matrix to be calculated.)\n",
    "\n",
    "Please submit your BO class (and GP class) along with the execution block as a .py file to the instructor. A different cell type (with different simulation parameters and maxima) will be used for scoring.\n",
    "\n",
    "This hackathon will be scored based on maximum titre concentration obtained at the highest fidelity. You must stay within the allocated budget! This will be checked, and if exceeded, your submission will be disqualified!\n",
    "\n",
    "#### Form of the BO class and execution block\n",
    "You are allowed to write your own BO class or make modifications to any of the previously seen BO classes. \n",
    "\n",
    "You must include the attributes `self.X` and `self.Y` corresponding to all of your evaluated inputs and outputs as this will be used to retrive the information used for scoring. \n",
    "\n",
    "```python\n",
    "#submission should look something like the following\n",
    "class GP: #if you have any separate classes other than the BO class\n",
    "    def __init__(self, ...):\n",
    "        ...\n",
    "#BO class\n",
    "class BO: \n",
    "    def __init__(self, ...):\n",
    "        self.X = #training data which the evaluated data is to be appended\n",
    "        self.Y = #evaluated via the objective function using self.X\n",
    "\n",
    "# BO Execution Block\n",
    "X_training = [...]\n",
    "X_seachspace = [...]\n",
    "\n",
    "BO_m = BO(...)\n",
    "```\n",
    "\n",
    "#### Guidance (Intermediate - Multi-batch Bayesian Optimsation) \n",
    "You can construct a single-sequential or batch BO algorithm to perform the optimisation. The lowest fidelity experiments do not offer accurate outcomes and you have to choose how many number of expeirments for each fidelity to be performed such that you do not exceed your allocated budget. To link between each fideility, one could perform optimisation on the lower fidilities and then translate the best input conditions to run the highest fidelity experiment. \n",
    "\n",
    "#### Guidance (Advanced - Multi-fidelity Bayesian Optimisation)\n",
    "You can develop a multi-fidelity Bayesian Optimisation algorithm to perform the optimisation. A basic MFBO algorithm could be created by modifying the acquisition function to one that is cost aware. For example: we have previously used Lower Confidence Bound to balance exploration and exploitation of the search space (see notebook section C). To make this cost aware, we can scale the values obtained from LCB by the cost.\n",
    "\n",
    "```python\n",
    "    def MF_lower_confidence_bound(...):\n",
    "        lower_std = Ysearchspace_mean - acquisition_hyperparam[0]*np.sqrt(Ysearchspace_std)\n",
    "        # mf_lower_std = lower_std / assocated cost for each simulation\n",
    "        return (X_searchspace[np.argmin(mf_lower_std)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd73484-4185-4126-8d42-fd3b5258cc61",
   "metadata": {},
   "source": [
    "#### Package Imports\n",
    "\n",
    "Packages are limited to the the ones listed in the package cell - Talk to one of the intructors to ask if it is possible to import other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977ab0af-7637-40a7-ab13-e7c3491d0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "import plotly.graph_objs as go\n",
    "from scipy.integrate import quad\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import minimize, differential_evolution, NonlinearConstraint\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "import time\n",
    "import sobol_seq\n",
    "import torch\n",
    "import gpytorch\n",
    "import copy\n",
    "\n",
    "from C_Bioprocess_Utils.virtual_lab import conduct_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae15efe-9687-418d-9b4d-32031d09ae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.35526663386677, 1.3630867118273524]\n"
     ]
    }
   ],
   "source": [
    "# Check that this runs without errors!\n",
    "\n",
    "def obj_func(X):\n",
    "\treturn (-np.array(conduct_experiment(X))) #negative placed if optimisation performed is minimisation\n",
    "\n",
    "X_initial = np.array([[33, 6.25, 10, 20, 20, 0],\n",
    "                      [38, 8, 20, 10, 20, 0]])\n",
    "Y_initial = conduct_experiment(X_initial)\n",
    "print(Y_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d6001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_botorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
