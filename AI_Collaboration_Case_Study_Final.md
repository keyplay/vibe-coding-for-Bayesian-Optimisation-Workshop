# 我和 AI 搭档打了一场生物过程优化 Hackathon

上周参加了一个 Hackathon，题目是用贝叶斯优化去调一个模拟的 CHO 细胞生物反应器，目标是在 15000 块虚拟预算内把蛋白产量（titre）拉到最高。五个输入变量：温度、pH、三次补料浓度（F1、F2、F3），外加三个保真度等级——便宜的小反应器跑一次 10 块，贵的大反应器跑一次 2100 块。

我全程用 AI 当编程搭档。18 轮指令下来，代码是 AI 写的，但方案是我们俩吵出来的。这篇文章记录这个过程，以及我从中学到的东西。

## 从 sklearn 到 BOTorch：好用的搬运工

最开始 AI 帮我搭了一个基于 sklearn 高斯过程的版本，跑通了。我问它能不能换成 BOTorch，它给了两个方案：纯 BOTorch 和混合方案（用 SingleTaskMultiFidelityGP 加上我们自己的分阶段预算策略）。我选了后者，因为我想保留对预算分配的控制权。

框架迁移这件事 AI 做得又快又好。SingleTaskMultiFidelityGP、qLogNoisyExpectedImprovement、FixedFeatureAcquisitionFunction，这些 API 我自己查文档可能要花半天，AI 几分钟就接好了。

但代码跑通不等于没问题。

## 核心发现：幽灵变量

低保真度（Fid 0）模拟的是 3L 小反应器，只在 t=60 分钟投一次料，用的是 F2。换句话说，F1 和 F3 在这个阶段压根不存在。模拟器接收这两个值，但内部直接忽略掉了。

中高保真度（Fid 1/2）不同，三次投料全都生效：F1 在 t=40，F2 在 t=80，F3 在 t=120。

AI 的种子迁移策略是把 Fid 0 的最优解整个向量复制给 Fid 1 作为搜索起点。数学上没毛病——都是六维向量，复制就完了。物理上就是灾难：Fid 0 里的 F1 和 F3 是垃圾数据，要么是 0，要么是 Sobol 序列随机出来的无意义数字。AI 把这些垃圾当宝贝传给了下一阶段。

Fid 1 单次实验 575。从一个错误起点开始搜索，可能要浪费好几次才能跑偏回来，几千块就没了。

我问了一句："低保真度实验的给料变量是不是只有 1 个？"AI 承认它没有考虑过这个问题。

## 物理直觉 vs. 纯随机

发现幽灵变量后，第一版修复方案是对 F1/F3 做全范围随机化（0 到 50）。合理，但我觉得还能更好。

我盯着投料时间看：Fid 0 在 t=60，Fid 1 在 t=40 和 t=80。

60 分钟刚好夹在 40 和 80 中间。生物反应是连续过程，细胞不会因为换了个反应器就突然改变代谢规律。t=60 的最优投料量，大概率和 t=40、t=80 的最优量有关系。

我告诉 AI：别全随机了，用 Fid 0 的 F2 当锚点，在附近搜。

AI 建议扰动范围 ±15。我想了想，手动改成了 ±5。

为什么？因为 575 块一次的实验容不得乱枪打鸟。而且生物动力学的连续性比 ±15 暗示的要强——40 分钟到 60 分钟不过是二十分钟的差别，细胞状态不会变化那么大。

后来我又把 F2 也加上了锚点参考（±5），F3 放宽到 ±10（因为 t=120 离 t=60 最远，相关性可能弱一些）。

## 五轮迭代才定下来的迁移策略

种子迁移这一块前后改了五版：

- v0：全部照搬。F1/F3 是垃圾数据，直接继承。
- v1：F1/F3 全范围随机。安全但低效。
- v2：F1 用锚点 ±15，F2/F3 随机。方向对了但测试得分反而下降。
- v3：F1 和 F2 都用锚点 ±15，F3 随机。
- v4：我手动收紧到 F1/F2 ±5，F3 ±10。
- v5：最后给温度加了 ±1°C，pH 加了 ±0.1 的抖动。

这个过程有意思的地方在于，v2 的得分反而变差了。当时只让 F1 参考锚点、F2 完全随机，等于在 t=80 这个位置丢掉了 t=60 的信息。改回 F1 和 F2 都参考锚点后才好转。这说明在有限预算下，信息利用的充分程度直接决定搜索效率。


## 我从这次搭档中学到了什么

### AI 是好工具，但它不理解"为什么"

整个过程中 AI 做得最好的事情是代码实现。BOTorch 的 API 调用、高斯过程拟合、采集函数配置——这些它又快又准。但它做不到的事情也很明确：它不会问"F1 在低保真度下到底有没有用"，不会看着时间轴琢磨 t=60 和 t=40 的关系，不会因为一次实验要花 575 块就变得谨慎。

这些都是领域知识和工程判断，目前还得靠人。

### 提问比写代码更值钱

回头看日志，推动项目前进的不是哪一段代码，而是几个问题：

- "低保真度的给料变量是不是只有 1 个"（发现幽灵变量）
- "但 60 与 40 和 80 都很接近，能否利用这点"（注入物理直觉）
- "迁移时给 T 和 pH 加一点小扰动"（防止局部最优）

每个问题背后是对物理过程的理解，而不是对代码的理解。AI 可以秒速实现任何一个想法，但它不会自己产生这些想法。

### "太听话"是一种风险

AI 从不反驳。你让它把无效变量复制过去，它就复制。你让它用 ±15 的扰动范围，它就用 ±15。它不会说"等一下，这个变量在低保真度下是无效的，你确定要直接复制吗？"

在 Hackathon 这种时间紧张的场景下，这种"太听话"很容易让人放松警惕。跑通了就觉得对了，但跑通和正确之间可能隔着几千块预算。

### 迭代比一步到位更现实

种子迁移策略改了五版才稳定。这不是因为我们笨，而是因为多保真度优化本身就充满了非显而易见的细节。Fid 0 和 Fid 1 之间的变量语义差异、投料时间的不一致、预算的非线性分配——这些问题不可能在第一版就全部预见到。

和 AI 搭档的好处是迭代的成本很低。发现问题，描述问题，AI 改代码，跑一轮测试，几分钟一个循环。如果全靠手写，光是 BOTorch 的 API 就够折腾一下午了。

## 写在最后

这次 Hackathon 让我对"人机协作"有了一个很具体的理解。AI 是一个打字速度无限快、API 文档全背下来的搭档，但它不懂你在做什么，也不知道什么时候该停下来想一想。

最终的方案（BOTorch + 基于时间相关性的种子迁移 + 手动调参的扰动范围）是 18 轮对话的产物。如果让 AI 自己跑，它大概会交出一个代码完整、逻辑自洽、但预算超支且搜索方向全错的方案。如果让我自己写，我大概还在翻 BOTorch 文档。

两个都不行的人凑在一起，结果还不错。
